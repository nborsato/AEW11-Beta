{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = pd.read_csv('speakers_planets.csv')\n",
    "abstracts = pd.read_csv('abstracts_all.csv')\n",
    "# housekeeping\n",
    "abstracts.rename(columns={'1. First Name':'First Name'}, inplace=True)\n",
    "abstracts.rename(columns={'2. Last Name':'Last Name'}, inplace=True)\n",
    "abstracts.rename(columns={'9. a) Please enter your TITLE for the 10th Australian Exoplanet Workshop':'Title'}, inplace=True)\n",
    "abstracts.rename(columns={'9. b) Please enter your ABSTRACT for the 10th Australian Exoplanet Workshop':'Abstract'}, inplace=True)\n",
    "# use a join to find speakers for thursday \n",
    "\n",
    "\n",
    "abstracts.rename(columns={'Last Name':'Thursday'}, inplace=True)\n",
    "thursday = pd.merge(abstracts, speakers, on='Thursday', how='right')\n",
    "# get rid of the abstracts that don't have a speaker\n",
    "thursday = thursday[thursday['Thursday'].notnull()]\n",
    "thursday.rename(columns={'Thursday':'Last Name'}, inplace=True)\n",
    "\n",
    "# now do friday\n",
    "abstracts.rename(columns={'Thursday':'Friday'}, inplace=True)\n",
    "friday = pd.merge(abstracts, speakers, on='Friday', how='right')\n",
    "friday = friday[friday['Friday'].notnull()]\n",
    "friday.rename(columns={'Friday':'Last Name'}, inplace=True)\n",
    "\n",
    "# now do the same for monday, tuesday, wednesday from speakers_stars.csv\n",
    "speakers_stars = pd.read_csv('speakers_stars.csv')\n",
    "\n",
    "abstracts.rename(columns={'Title':'Planets Title'}, inplace=True)\n",
    "abstracts.rename(columns={'Abstract':'Planets Abstract'}, inplace=True)\n",
    "abstracts.rename(columns={'8. a) Please enter your TITLE for Stars in Brisbane':'Title'}, inplace=True)\n",
    "abstracts.rename(columns={'8. b) Please enter your ABSTRACT for Stars in Brisbane':'Abstract'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# now do monday, tuesday, wednesday\n",
    "abstracts.rename(columns={'Friday':'Monday'}, inplace=True)\n",
    "monday = pd.merge(abstracts, speakers_stars, on='Monday', how='right')\n",
    "monday = monday[monday['Monday'].notnull()]\n",
    "monday.rename(columns={'Monday':'Last Name'}, inplace=True)\n",
    "\n",
    "abstracts.rename(columns={'Monday':'Tuesday'}, inplace=True)\n",
    "tuesday = pd.merge(abstracts, speakers_stars, on='Tuesday', how='right')\n",
    "tuesday = tuesday[tuesday['Tuesday'].notnull()]\n",
    "tuesday.rename(columns={'Tuesday':'Last Name'}, inplace=True)\n",
    "\n",
    "abstracts.rename(columns={'Tuesday':'Wednesday'}, inplace=True)\n",
    "wednesday = pd.merge(abstracts, speakers_stars, on='Wednesday', how='right')\n",
    "wednesday = wednesday[wednesday['Wednesday'].notnull()]\n",
    "wednesday.rename(columns={'Wednesday':'Last Name'}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email Address', 'First Name', 'Wednesday', '3. Current Institution',\n",
       "       '4. Career Level', '5. Gender',\n",
       "       '7. Which workshop are you submitting an abstract for?', 'Title',\n",
       "       'Planets Title',\n",
       "       '10. Would you prefer to present a talk or a poster for Stars in Brisbane?',\n",
       "       '12. Have you registered for the event(s) for which you are submitting the abstract(s) ?',\n",
       "       '11. If your abstract is not selected for a talk, would you like to present it as a poster?',\n",
       "       '10. Would you prefer to present a talk or a poster for the 10th Australian Exoplanet Workshop?',\n",
       "       'Abstract', 'Planets Abstract', 'If your abstract is not'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeremy Bailey\n",
      "Adithya Balasubramaniam\n",
      "Laura Venuti\n",
      "Peter Tuthill\n",
      "Courtney Crawford\n",
      "Tania Ahmed\n",
      "Ana Lourdes Juarez Garcia\n",
      "Barnali Das\n",
      "Yuzhe Song\n",
      "Ryan White\n",
      "Sarah Martell\n",
      "Alexander Venner\n",
      "John Bray\n",
      "Jacinda Webb\n",
      "Brad Carter\n",
      "Alex Wallace\n",
      "Han Shen\n",
      "Evgeni Grishin\n",
      "Daniel Zucker\n",
      "Emma Brown\n",
      "Nicolas Rodriguez-Segovia\n",
      "Richard de Grijs\n",
      "Ivey Davis\n",
      "Anuj Gautam\n",
      "Maksym Mohorian\n",
      "May Gade Pedersen\n",
      "Stephen Neilson\n",
      "Chunliang Mu\n",
      "Dennis Stello\n",
      "Erica Thygesen\n",
      "Jack Nibbs\n",
      "Laura Driessen\n",
      "Yuzhe Song\n",
      "Kayla Martin\n",
      "Mark Walker\n",
      "Deepak Chahal\n",
      "Meghna Menon\n",
      "Tara Murphy\n",
      "Taissa Danilovich\n",
      "Katelyn Smith\n",
      "Alexander Csukai\n",
      "Barnali Das\n",
      "Amanda Karakas\n",
      "Conaire Deagan\n",
      "Harmeen Kaur\n",
      "Shishir Dholakia\n",
      "Ryosuke Hirai\n",
      "Sven Buder\n",
      "Christophe Pinte\n",
      "Stephen Kane\n",
      "Evgeni Grishin\n",
      "Ava Morrissey\n",
      "Tyler Fairnington\n",
      "Nicholas Borsato\n",
      "Sydney Vach\n",
      "Iain Hammond\n",
      "Ben Montet\n",
      "Louis Desdoigts\n",
      "Sakhee Bhure\n",
      "Max Charles\n",
      "Patryk Sofia Lykawka\n",
      "Brendan McKee\n",
      "Thomas Hilder\n",
      "Thomas Plunkett\n",
      "Peter Tuthill\n",
      "Rachel Harrison\n",
      "Jeremy Bailey\n",
      "Jonti Horner\n",
      "Jean-Philippe Beaulieu\n",
      "Priyashkumar Mistry\n",
      "Stephanie Rossini-Bryson\n",
      "Grace Piroscia\n",
      "Natalia Rektsini\n",
      "Caitlyn Hardiman\n",
      "Markdown schedule and speaker pages generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# both \n",
    "\n",
    "def generate_markdown_for_conference(conference_name, days_df, schedule_days,programme=\"planets\"):\n",
    "    \"\"\"\n",
    "    Generate markdown table for a single conference.\n",
    "    \"\"\"\n",
    "    # Initialize the Hugo table content with headers\n",
    "    hugo_table = f'---\\ntitle: Programme - {programme.capitalize()}\\n'\n",
    "    hugo_table += \"menu: {main: {weight: 30}}\\ndate: 2024-10-08\\n---\"\n",
    "    hugo_table += \"\\n{{% blocks/cover title=\" + f'\"Programme - {programme.capitalize()}\" ' + 'image_anchor=\"top\" height=\"full\" %}}\\n'\n",
    "    hugo_table += f\"## {conference_name}\\n\\n\"\n",
    "    hugo_table += \"| Schedule | \" + \" | \".join([day.capitalize() for day in schedule_days]) + \" |\\n\"\n",
    "    hugo_table += \"| -------- | \" + \" | \".join([\"----------------\"] * len(schedule_days)) + \" |\\n\"\n",
    "\n",
    "    # Combine the schedules from all days\n",
    "    all_schedules = sorted(set().union(*[set(df['Schedule']) for df in days_df]))\n",
    "\n",
    "    for schedule in all_schedules:\n",
    "        row = f\"| {schedule} |\"\n",
    "        for df in days_df:\n",
    "            speaker_row = df[df['Schedule'] == schedule]\n",
    "            if not speaker_row.empty:\n",
    "                speaker = speaker_row.iloc[0]\n",
    "                full_name = f\"{speaker['First Name']} {speaker['Last Name']}\"\n",
    "                print(full_name)\n",
    "                slug = f\"{speaker['First Name'].lower().replace(' ','-')}-{speaker['Last Name'].lower().replace(' ', '-')}\"\n",
    "                link = f\"[{full_name}](speakers/{slug}/_index.md)\"\n",
    "                row += f\" {link} |\"\n",
    "                # Create individual markdown page for the speaker\n",
    "                create_speaker_markdown(speaker_row,slug,programme=programme)\n",
    "\n",
    "            else:\n",
    "                row += \" |\"  # Empty cell if no speaker at this time\n",
    "        hugo_table += row + \"\\n\"\n",
    "    hugo_table += \"\\n{{% /blocks/cover %}}\"\n",
    "\n",
    "    return hugo_table\n",
    "\n",
    "\n",
    "def create_speaker_markdown(speaker_row, slug,programme=\"planets\"):\n",
    "    \"\"\"Creates a markdown page for an individual speaker.\"\"\"\n",
    "    # Extract the actual values from the pandas Series\n",
    "    first_name = speaker_row['First Name'].values[0] if not speaker_row['First Name'].isnull().all() else \"\"\n",
    "    last_name = speaker_row['Last Name'].values[0] if not speaker_row['Last Name'].isnull().all() else \"\"\n",
    "    title = speaker_row['Title'].values[0] if not speaker_row['Title'].isnull().all() else \"No Title Available\"\n",
    "    if title == \"No Title Available\":\n",
    "        try:\n",
    "            title = speaker_row['Planets Title'].values[0] if not speaker_row['Planets Title'].isnull().all() else \"No Title Available\"\n",
    "        except:\n",
    "            print(f\"Warning: No title available for {first_name} {last_name}\")\n",
    "    abstract = speaker_row['Abstract'].values[0] if not speaker_row['Abstract'].isnull().all() else \"No Abstract Available\"\n",
    "    if abstract == \"No Abstract Available\":\n",
    "        try:\n",
    "            abstract = speaker_row['Planets Abstract'].values[0] if not speaker_row['Planets Abstract'].isnull().all() else \"No Abstract Available\"\n",
    "        except:\n",
    "            print(f\"Warning: No abstract available for {first_name} {last_name}\")\n",
    "\n",
    "    # Full name\n",
    "    full_name = f\"{first_name} {last_name}\"\n",
    "\n",
    "    pre, post = r'{{% blocks/cover title=\"Placeholder\" image_anchor=\"top\" height=\"full\" %}}'.replace(\"Placeholder\", full_name), r\"{{% /blocks/cover %}}\"\n",
    "\n",
    "    # Generate the markdown content\n",
    "    speaker_md = f\"\"\"---\n",
    "title: \"{full_name}\"\n",
    "date: 2024-10-08\n",
    "---\n",
    "\n",
    "{pre}\n",
    "\n",
    "## {title}\n",
    "\n",
    "{abstract}\n",
    "\n",
    "{post}\n",
    "                    \"\"\"\n",
    "    # Write the speaker's markdown file\n",
    "    outdir = f\"../content/en/programme_{programme}/speakers/\"\n",
    "    os.makedirs(os.path.join(outdir, slug), exist_ok=True)\n",
    "    speaker_md_filename = os.path.join(outdir, f\"{slug}/_index.md\".replace(\" \", \"-\"))\n",
    "    with open(speaker_md_filename, 'w') as speaker_file:\n",
    "        speaker_file.write(speaker_md)\n",
    "    # copy featured-background.jpg from here to the speaker's directory using os\n",
    "    os.system(f\"cp featured-background.jpg {os.path.join(outdir, slug)}\")\n",
    "    \n",
    "\n",
    "\n",
    "def generate_markdown_for_both_conferences(stars_dfs, exoplanets_dfs, stars_days, exoplanets_days):\n",
    "    # Ensure the speaker directory exists\n",
    "    os.makedirs(\"speakers\", exist_ok=True)\n",
    "\n",
    "    # Generate markdown tables for both conferences\n",
    "    stars_table = generate_markdown_for_conference(\"Stars in Brisbane\", stars_dfs, stars_days,programme=\"stars\")\n",
    "\n",
    "    # Write the stars markdown table to a file\n",
    "    with open('../content/en/programme_stars/_index.md', 'w') as file:\n",
    "        file.write(stars_table)\n",
    "\n",
    "    exoplanets_table = generate_markdown_for_conference(\"Australian Exoplanet Workshop\", exoplanets_dfs, exoplanets_days,programme=\"planets\")\n",
    "\n",
    "    # Write the exoplanets markdown table to a file\n",
    "    with open('../content/en/programme_planets/_index.md', 'w') as file:\n",
    "        file.write(exoplanets_table)\n",
    "\n",
    "    print(\"Markdown schedule and speaker pages generated successfully.\")\n",
    "\n",
    "# Assuming `monday`, `tuesday`, `wednesday`, `thursday`, and `friday` are the dataframes\n",
    "# Lists of dataframes for each conference\n",
    "stars_dfs = [monday, tuesday, wednesday]\n",
    "exoplanets_dfs = [thursday, friday]\n",
    "\n",
    "# Days for each conference\n",
    "stars_days = ['monday', 'tuesday', 'wednesday']\n",
    "exoplanets_days = ['thursday', 'friday']\n",
    "\n",
    "# Generate the combined markdown file\n",
    "generate_markdown_for_both_conferences(stars_dfs, exoplanets_dfs, stars_days, exoplanets_days);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from pathlib import Path\n",
    "\n",
    "# def convert_markdown_to_latex(markdown_content):\n",
    "#     # Convert the header\n",
    "#     latex_content = r\"\\documentclass{article}\" + \"\\n\" + r\"\\usepackage{longtable}\" + \"\\n\" + r\"\\usepackage{hyperref}\" + \"\\n\" + r\"\\usepackage{geometry}\" + \"\\n\" + r\"\\geometry{a4paper, margin=1in}\" + \"\\n\" + r\"\\begin{document}\" + \"\\n\"\n",
    "    \n",
    "#     # Extract title\n",
    "#     title_match = re.search(r'title:\\s*(.*)', markdown_content)\n",
    "#     if title_match:\n",
    "#         title = title_match.group(1).strip()\n",
    "#         latex_content += r\"\\title{\" + title + \"}\\n\" + r\"\\maketitle\" + \"\\n\"\n",
    "    \n",
    "#     # Convert Markdown links to LaTeX \\href\n",
    "#     markdown_content = re.sub(r'\\[([^\\]]+)\\]\\(([^)]+)\\)', r'\\\\href{\\2}{\\1}', markdown_content)\n",
    "    \n",
    "#     # Extract sections\n",
    "#     sections = re.split(r'#\\s+', markdown_content)\n",
    "#     for section in sections:\n",
    "#         if section.strip():\n",
    "#             # Extract section title\n",
    "#             section_title_match = re.match(r'([^\\n]+)', section)\n",
    "#             if section_title_match:\n",
    "#                 section_title = section_title_match.group(1).strip()\n",
    "#                 latex_content += r\"\\section{\" + section_title + \"}\\n\"\n",
    "            \n",
    "#             # Extract tables\n",
    "#             tables = re.findall(r'\\|.*\\|', section)\n",
    "#             for table in tables:\n",
    "#                 rows = table.strip().split('\\n')\n",
    "#                 latex_content += r\"\\begin{longtable}{|\" + \" | \".join(['c'] * len(rows[0].split('|'))) + r\"|}\" + \"\\n\"\n",
    "#                 latex_content += r\"\\hline\" + \"\\n\"\n",
    "#                 for row in rows:\n",
    "#                     columns = row.split('|')[1:-1]\n",
    "#                     latex_content += \" & \".join([col.strip() for col in columns]) + r\" \\\\\" + \"\\n\"\n",
    "#                     latex_content += r\"\\hline\" + \"\\n\"\n",
    "#                 latex_content += r\"\\end{longtable}\" + \"\\n\"\n",
    "    \n",
    "#     latex_content += r\"\\end{document}\"\n",
    "#     return latex_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# txt = Path('../content/en/programme/_index.md').read_text()\n",
    "\n",
    "# # Write to a .tex file\n",
    "# output_path = Path('output.tex')\n",
    "# output_path.write_text(convert_markdown_to_latex(txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
